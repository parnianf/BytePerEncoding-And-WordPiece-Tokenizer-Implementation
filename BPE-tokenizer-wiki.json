{
  "version": "1.0",
  "truncation": null,
  "padding": null,
  "added_tokens": [],
  "normalizer": null,
  "pre_tokenizer": {
    "type": "Whitespace"
  },
  "post_processor": null,
  "decoder": null,
  "model": {
    "type": "BPE",
    "dropout": null,
    "unk_token": null,
    "continuing_subword_prefix": null,
    "end_of_word_suffix": null,
    "fuse_unk": false,
    "vocab": {
      "!": 0,
      ".": 1,
      "?": 2,
      "E": 3,
      "L": 4,
      "N": 5,
      "P": 6,
      "T": 7,
      "W": 8,
      "a": 9,
      "b": 10,
      "c": 11,
      "d": 12,
      "e": 13,
      "f": 14,
      "g": 15,
      "h": 16,
      "i": 17,
      "k": 18,
      "l": 19,
      "m": 20,
      "n": 21,
      "o": 22,
      "p": 23,
      "r": 24,
      "s": 25,
      "t": 26,
      "u": 27,
      "w": 28,
      "x": 29,
      "y": 30,
      "z": 31,
      "en": 32,
      "in": 33,
      "at": 34,
      "ken": 35,
      "oken": 36,
      "ar": 37,
      "de": 38,
      "ep": 39,
      "io": 40,
      "is": 41,
      "iz": 42,
      "token": 43,
      "ing": 44,
      "atio": 45,
      "izatio": 46,
      "ization": 47,
      "ch": 48,
      "ed": 49,
      "ear": 50,
      "he": 51,
      "lear": 52,
      "ning": 53,
      "st": 54,
      "the": 55,
      "deep": 56,
      "tokenization": 57,
      "learning": 58,
      "?!": 59,
      "Ex": 60,
      "LP": 61,
      "NLP": 62,
      "Th": 63,
      "Token": 64,
      "We": 65,
      "al": 66,
      "ach": 67,
      "be": 68,
      "by": 69,
      "ci": 70,
      "co": 71,
      "el": 72,
      "er": 73,
      "each": 74,
      "fi": 75,
      "gen": 76,
      "il": 77,
      "ip": 78,
      "ial": 79,
      "mo": 80,
      "mp": 81,
      "mu": 82,
      "or": 83,
      "pip": 84,
      "rst": 85,
      "tu": 86,
      "ted": 87,
      "tor": 88,
      "wil": 89,
      "ine": 90,
      "ated": 91,
      "aring": 92,
      "del": 93,
      "tokens": 94,
      "step": 95,
      "Exci": 96,
      "This": 97,
      "Tokenization": 98,
      "comp": 99,
      "eline": 100,
      "erated": 101,
      "first": 102,
      "generated": 103,
      "model": 104,
      "much": 105,
      "pipeline": 106,
      "tutor": 107,
      "will": 108,
      "Excited": 109,
      "comparing": 110,
      "tutorial": 111
    },
    "merges": [
      "e n",
      "i n",
      "a t",
      "k en",
      "o ken",
      "a r",
      "d e",
      "e p",
      "i o",
      "i s",
      "i z",
      "t oken",
      "in g",
      "at io",
      "iz atio",
      "izatio n",
      "c h",
      "e d",
      "e ar",
      "h e",
      "l ear",
      "n ing",
      "s t",
      "t he",
      "de ep",
      "token ization",
      "lear ning",
      "? !",
      "E x",
      "L P",
      "N LP",
      "T h",
      "T oken",
      "W e",
      "a l",
      "a ch",
      "b e",
      "b y",
      "c i",
      "c o",
      "e l",
      "e r",
      "e ach",
      "f i",
      "g en",
      "i l",
      "i p",
      "i al",
      "m o",
      "m p",
      "m u",
      "o r",
      "p ip",
      "r st",
      "t u",
      "t ed",
      "t or",
      "w il",
      "in e",
      "at ed",
      "ar ing",
      "de l",
      "token s",
      "st ep",
      "Ex ci",
      "Th is",
      "Token ization",
      "co mp",
      "el ine",
      "er ated",
      "fi rst",
      "gen erated",
      "mo del",
      "mu ch",
      "pip eline",
      "tu tor",
      "wil l",
      "Exci ted",
      "comp aring",
      "tutor ial"
    ]
  }
}